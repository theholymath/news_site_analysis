{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feedparser\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import sqlite3\n",
    "import json\n",
    "import concurrent.futures\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent = 4)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "form = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _create_db_and_initialize_tables():\n",
    "    # create db\n",
    "    db = sqlite3.connect('data/NewsSiteRSSFeeds.db')\n",
    "\n",
    "    # Get a cursor object\n",
    "    cursor = db.cursor()\n",
    "\n",
    "    # Note to self - never use python's string operations for db interface: insecure\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS sources(id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, ideology TEXT, \n",
    "                             url TEXT, rss_feed_url TEXT unique)\n",
    "                   ''')\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS sources_data(id INTEGER PRIMARY KEY, \n",
    "        sources_id INTEGER, date TEXT, title TEXT, summary TEXT,\n",
    "        UNIQUE(title))\n",
    "                   ''')\n",
    "    db.commit()\n",
    "    db.close()\n",
    "\n",
    "def _fill_sources_table(filename):\n",
    "    # open connection\n",
    "    db = sqlite3.connect('data/NewsSiteRSSFeeds.db')\n",
    "    cursor = db.cursor()\n",
    "    \n",
    "    # grab dictionary from json file\n",
    "    with open(filename) as json_data:\n",
    "        data = json.load(json_data)\n",
    "\n",
    "    list_to_commit = []\n",
    "    \n",
    "    # write to database - can't use zip here\n",
    "    keys = [\"C\",\"L\",\"O\"]\n",
    "    \n",
    "    for ideology in keys:\n",
    "        names = data[ideology]\n",
    "        \n",
    "        for name in names:\n",
    "            tup = (name,ideology,data[ideology][name][\"url\"],data[ideology][name][\"feed_url\"])\n",
    "            list_to_commit.append(tup)\n",
    "        \n",
    "    cursor.executemany('INSERT OR IGNORE INTO sources(name,ideology,url,rss_feed_url) VALUES (?,?,?,?)',list_to_commit)\n",
    "    db.commit()\n",
    "    db.close()\n",
    "    \n",
    "def _fill_sources_data_table(filename):\n",
    "    # open connection\n",
    "    db = sqlite3.connect('data/NewsSiteRSSFeeds.db')\n",
    "    cursor = db.cursor()\n",
    "\n",
    "    list_to_commit = []\n",
    "    \n",
    "    tup = (name,ideology,data[ideology][name][\"url\"],data[ideology][name][\"feed_url\"])\n",
    "    list_to_commit.append(tup)\n",
    "        \n",
    "    cursor.executemany('INSERT OR IGNORE INTO sources_data(sources_id,date,title,summary) VALUES (?,?,?,?)',list_to_commit)\n",
    "    db.commit()\n",
    "    db.close()\n",
    "    \n",
    "def _get_rss_feed_list():\n",
    "    db = sqlite3.connect('data/NewsSiteRSSFeeds.db')\n",
    "    cursor = db.cursor()\n",
    "    rss_feed_list = [url for url in cursor.execute('SELECT rss_feed_url FROM sources')]\n",
    "    db.close()\n",
    "    \n",
    "    return rss_feed_list\n",
    "\n",
    "def _get_feedparsed_site(url):\n",
    "    return feedparser.parse(url)\n",
    "\n",
    "# old synchronous way to fill db table\n",
    "def add_headlineText_to_DB(rss_feed_list):\n",
    "    # open connection\n",
    "    db = sqlite3.connect('data/NewsSiteRSSFeeds.db')\n",
    "    cursor = db.cursor()\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    time_to_enter = now.strftime(form)\n",
    "\n",
    "    for site in rss_feed_list:\n",
    "        # get source_id from table of news sources\n",
    "        sources_id = cursor.execute('SELECT id FROM sources WHERE rss_feed_url = ?',(site)).fetchone()[0]\n",
    "        d = feedparser.parse(site[0])\n",
    "        list_to_commit = []\n",
    "        for entry in d['entries']:\n",
    "            title   = entry['title']\n",
    "            summary = entry['summary'].encode('utf-8')\n",
    "            try:\n",
    "                published = entry['published']\n",
    "            except KeyError:\n",
    "                published = time_to_enter\n",
    "            tup     = (int(sources_id),published,str(title),str(summary))\n",
    "            list_to_commit.append(tup)\n",
    "        \n",
    "        cursor.executemany('INSERT OR IGNORE INTO sources_data(sources_id,date,title,summary) VALUES (?,?,?,?)',list_to_commit)\n",
    "\n",
    "        db.commit()\n",
    "    db.close()\n",
    "    \n",
    "async def add_headlineText_to_DB_async(rss_feed_list):\n",
    "    now = datetime.datetime.now()\n",
    "    time_to_enter = now.strftime(form)\n",
    "    \n",
    "    db = sqlite3.connect('data/NewsSiteRSSFeeds.db')\n",
    "    cursor = db.cursor()\n",
    "        \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for site in rss_feed_list:\n",
    "            \n",
    "            if type(site) == tuple:\n",
    "                sources_id = cursor.execute('SELECT id FROM sources WHERE rss_feed_url = ?',(site)).fetchone()[0]\n",
    "                site = site[0]\n",
    "            \n",
    "            list_to_commit = []\n",
    "            \n",
    "            async with session.get(site) as resp:\n",
    "                text = await resp.text()\n",
    "                feed = feedparser.parse(text)\n",
    "                \n",
    "                for entry in feed['entries']:\n",
    "                    title   = entry['title']\n",
    "                    summary = entry['summary'].encode('utf-8')\n",
    "                    \n",
    "                    try:\n",
    "                        published = entry['published']\n",
    "                    except KeyError:\n",
    "                        published = time_to_enter\n",
    "                    tup     = (int(sources_id),published,str(title),str(summary))\n",
    "                    list_to_commit.append(tup)\n",
    "        \n",
    "            cursor.executemany('INSERT OR IGNORE INTO sources_data(sources_id,date,title,summary) VALUES (?,?,?,?)',list_to_commit)\n",
    "            db.commit()\n",
    "    db.close()\n",
    "    \n",
    "async def add_headlineText_to_DB_async_concurrent(rss_feed_list):\n",
    "    now = datetime.datetime.now()\n",
    "    time_to_enter = now.strftime(form)\n",
    "    db = sqlite3.connect('data/NewsSiteRSSFeeds.db')\n",
    "    cursor = db.cursor()\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "\n",
    "        loop = asyncio.get_event_loop()\n",
    "        futures = []\n",
    "        #for site in rss_feed_list:\n",
    "        for site in rss_feed_list:\n",
    "            sources_id = cursor.execute('SELECT id FROM sources WHERE rss_feed_url = ?',(site)).fetchone()[0]\n",
    "            futures.append(loop.run_in_executor(\n",
    "                    executor, \n",
    "                    requests.get, \n",
    "                    site[0])\n",
    "                          )\n",
    "        for response in await asyncio.gather(*futures):\n",
    "            feed = feedparser.parse(response.text)\n",
    "            list_to_commit = []\n",
    "            \n",
    "            for entry in feed['entries']:\n",
    "                title   = entry['title']\n",
    "                summary = entry['summary'].encode('utf-8')\n",
    "\n",
    "                try:\n",
    "                    published = entry['published']\n",
    "                except KeyError:\n",
    "                    published = time_to_enter\n",
    "                tup     = (int(sources_id),published,str(title),str(summary))\n",
    "                list_to_commit.append(tup)\n",
    "            cursor.executemany('INSERT OR IGNORE INTO sources_data(sources_id,date,title,summary) VALUES (?,?,?,?)',list_to_commit)\n",
    "            db.commit()\n",
    "    db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19015 ms\n"
     ]
    }
   ],
   "source": [
    "_create_db_and_initialize_tables()\n",
    "_fill_sources_table('news_feed_dict.json')\n",
    "rss_feed_list = _get_rss_feed_list()\n",
    "startTime = int(round(time.time() * 1000))\n",
    "add_headlineText_to_DB(rss_feed_list)\n",
    "endTime = int(round(time.time() * 1000))\n",
    "\n",
    "print(endTime - startTime,'ms')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startTime = int(round(time.time() * 1000))\n",
    "\n",
    "asyncio.set_event_loop(asyncio.new_event_loop()) # need to have global loop open\n",
    "loop = asyncio.get_event_loop()\n",
    "#loop.run_until_complete(test_get_function(rss_feed_list))\n",
    "try:\n",
    "    loop.run_until_complete(add_headlineText_to_DB_async(rss_feed_list))\n",
    "finally:\n",
    "    loop.close()\n",
    "endTime = int(round(time.time() * 1000))\n",
    "\n",
    "print(endTime - startTime,'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14998 ms\n"
     ]
    }
   ],
   "source": [
    "startTime = int(round(time.time() * 1000))\n",
    "\n",
    "asyncio.set_event_loop(asyncio.new_event_loop()) # need to have global loop open\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "try:\n",
    "    loop.run_until_complete(add_headlineText_to_DB_async_concurrent(rss_feed_list))\n",
    "finally:\n",
    "    loop.close()\n",
    "endTime = int(round(time.time() * 1000))\n",
    "\n",
    "print(endTime - startTime,'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3771 ms\n"
     ]
    }
   ],
   "source": [
    "# check data\n",
    "db = sqlite3.connect('data/NewsSiteRSSFeeds.db')\n",
    "cursor = db.cursor()\n",
    "for row in cursor.execute('SELECT * FROM sources_data'):\n",
    "    print(row[0])\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('data/NewsSiteRSSFeeds.db')\n",
    "cursor = db.cursor()\n",
    "for i,row in enumerate(cursor.execute('SELECT DISTINCT title FROM sources_data')):\n",
    "    print(i)#,row[0])\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
